{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Statistical Learning \n",
    "Introduction to Statistical Learning by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani is considered a canonical text in the field of statistical/machine learning and is an absolutely fantastic way to move forward in your analytics career. [The text is free to download](http://www-bcf.usc.edu/~gareth/ISL/) and an [online course by the authors themselves](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about) is currently available in self-pace mode, meaning you can complete it any time. Make sure to **[REGISTER FOR THE STANDFORD COURSE!](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about)** The videos have also been [archived here on youtube](http://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/).\n",
    "\n",
    "# How will Houston Data Science cover the course?\n",
    "The Stanford online course covers the entire book in 9 weeks and with the R programming language. The pace that we cover the book is yet to be determined as there are many unknown variables such as interest from members, availability of a venue and general level of skills of those participating. That said, a meeting once per week to discuss the current chapter or previous chapter solutions is the target.\n",
    "\n",
    "\n",
    "# Python in place of R\n",
    "Although R is a fantastic programming language and is the language that all the ISLR labs are written in, the Python programming language, except for rare exceptions, contains analgous libraries that contain the same statistical functionality as those in R.\n",
    "\n",
    "# Notes, Exercises and Programming Assignments all in the Jupyter Notebok\n",
    "ISLR has both end of chapter problems and programming assignments. All chapter problems and programming assignments will be answered in the notebook.\n",
    "\n",
    "# Replicating Plots\n",
    "The plots in ISLR are created in R. Many of them will be replicated here in the notebook when they appear in the text\n",
    "\n",
    "# Book Data\n",
    "The data from the books was downloaded using R. All the datasets are found in either the MASS or ISLR packages. They are now in the data directory. See below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAdvertising.csv\u001b[m\u001b[m caravan.csv     hitters.csv     khan_ytrain.csv smarket.csv\r\n",
      "Credit.csv      carseats.csv    khan_xtest.csv  nci60_data.csv  usarrests.csv\r\n",
      "auto.csv        college.csv     khan_xtrain.csv nci60_labs.csv  \u001b[31mwage.csv\u001b[m\u001b[m\r\n",
      "boston.csv      default.csv     khan_ytest.csv  portfolio.csv   weekly.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISLR Videos\n",
    "[All Old Videos](https://www.r-bloggers.com/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 Resampling Methods\n",
    "Covers resampling data through bootstraping and cross validation. Cross validation gets us an error estimate for our test data and boostraping provides estimates for parameter accuracy.\n",
    "\n",
    "### Cross Validation\n",
    "Usually a test set is not available so a simple strategy to create one is to split the available data into training and testing (validation set). For quantitative responses usually use MSE, for categorical can use error rate, area under the curve, F1 score, weighting of confusion matrix, etc...\n",
    "\n",
    "### Leave One Out Cross Validation\n",
    "LOOCV has only one observation in the test set and uses all other n-1 observations to build a model. n different models are built leaving out each observation once and error is averaged over these n trials.  LOOCV is better than simple method above. Model is built on nearly all the data and there is no randomness in the splits since each observation will be left out once. It is computationally expensive especially with large n and a complex model.\n",
    "\n",
    "### k-fold cross validation\n",
    "Similar to LOOCV but this time you leave some number greater than 1 out. Here, k is the number of partitions of your sample, so if you have 1000 obsevations and k = 10, the each fold will be 100. These 100 observations would act as your test set. Get an MSE for each fold of these 100 observations and take the average. LOOCV is a special case of k-fold CV whenever k equals the number of observations.\n",
    "\n",
    "### bias-variance tradeoff between LOOCV and k-folds\n",
    "Since LOOCV trains on nearly all the data, the test error rate will generally be lower than k-fold and there for less biased. LOOCV will have higher variance since all n models will be very highly correlated to one another. Since the models won't differ much, the test error rate (which what CV is measuring) will vary more than k-fold which has fewer models that are less correlated with one another. A value of k between 5 and 10 is a good rule of thumb that balances the tradeoff between bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can do example where LOOCV has higher variance than k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "Minimize $$Var(\\alpha X + (1 - \\alpha)Y)$$\n",
    "\n",
    "Properties of variance and covariance\n",
    "$$=Var(\\alpha X) + Var((1 - \\alpha)Y) + 2Cov(\\alpha X, (1 - \\alpha)Y)$$\n",
    "$$=\\alpha^2Var(X) + (1 - \\alpha)^2Var(Y) + 2(\\alpha)(1 - \\alpha)(Cov(X, Y)$$\n",
    "\n",
    "Take derivative and set to 0\n",
    "$$2\\alpha Var(X) - 2(1 - \\alpha)Var(Y) + (2 - 4\\alpha)Cov(X, Y) = 0$$\n",
    "Collect terms\n",
    "$$2\\alpha Var(X) + 2 \\alpha Var(Y) - 4\\alpha Cov(X, Y) = 2Var(Y) - 2Cov(X, Y)$$\n",
    "Solve for $\\alpha$\n",
    "$$\\alpha = \\frac{Var(Y) - Cov(X, Y)}{Var(X) + Var(Y) - 2Cov(X, Y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n",
    "a) $\\frac{n-1}{n}$  \n",
    "b) $\\frac{n-1}{n}$  \n",
    "c) Since bootstrapping is sampling with replace, the probability of being any jth obsevation is $\\frac{1}{n}$. The probability of not being the jth observation is $1 - \\frac{1}{n}$. Since each draw is independent we can just multiply the probabilities together to get the probability that the jth observation is not in the sample at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3276800000000001,\n",
       " 0.3660323412732292,\n",
       " 0.36786104643297046,\n",
       " 0.3678776017682465]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 c-f\n",
    "[(1 - 1/n) **n for n in [5, 100, 10000, 100000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(1, 100001)\n",
    "y = (1 - 1/x) ** x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x880b898>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb2bWRBz6ZmZNxKFvZtZE/j/W7KNr5UA+VQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x87b2550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[:10], y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63239999999999996"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2h\n",
    "# make 10,000 samples of 100 elements each sample from integers 1 - 100\n",
    "# check if 4 is each sample. Take mean.\n",
    "# Looks like very close to theoretical probability\n",
    "data = np.random.randint(1, 101, (100, 10000))\n",
    "np.any(data == 4, axis=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "a) K-fold CV works by taking the dataset given and randomly splitting it into k non-overlapping datasets. You can shuffle the data first and then just split at regular intervals. Train K models. For each model, use the kth region as the validation set and build on the other k-1 sets. Take the mean of the k errors found to estimate the true test error.  \n",
    "\n",
    "b i) Advantage to validation set is that there are more test sets to validate on which should reduce the bias of what the overall error actually is. Variance should also decrease as the validation set approach is just one split of the data and that split could not represent the test data well. Disadvantage is training more models.  \n",
    "\n",
    "b ii) Advantage to LOOCV is a decrease in variance as the k models are not as highly correlated as the each LOOCV model is. Also, K-folds is computationally less expensive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4\n",
    "* Before bootstrapping, you can build a single model using k-fold cross validation.\n",
    "* Now using the bootstrap, create 10,000 samples of all your data and find a mean error for each sample. \n",
    "* Comute standard error based on mean error of each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default = pd.read_csv('data/default.csv').iloc[:, 1:]\n",
    "default['student_yes'] = pd.get_dummies(default['student'], drop_first=True).values.astype('int')\n",
    "default['default_yes'] = pd.get_dummies(default['default'], drop_first=True).values.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>student_yes</th>\n",
       "      <th>default_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income  student_yes  default_yes\n",
       "0      No      No   729.526495  44361.625074            0            0\n",
       "1      No     Yes   817.180407  12106.134700            1            0\n",
       "2      No      No  1073.549164  31767.138947            0            0\n",
       "3      No      No   529.250605  35704.493935            0            0\n",
       "4      No      No   785.655883  38463.495879            0            0"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = default[['balance', 'income']]\n",
    "y = default['default_yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-11.52731503]), array([[  5.64078217e-03,   2.07265906e-05]]))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice how tol must be changed to less than default value or convergence won't happen\n",
    "# Use a high value of C to remove regularization\n",
    "model = LogisticRegression(C=100000, tol=.0000001)\n",
    "model.fit(X, y)\n",
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels\n",
    "Coefficients are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "result = smf.logit(formula='default_yes ~ balance + income', data=default).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>default_yes</td>   <th>  No. Observations:  </th>   <td> 10000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 30 Aug 2016</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:19:06</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393   -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005     0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05  3.06e-05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            default_yes   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9997\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Tue, 30 Aug 2016   Pseudo R-squ.:                  0.4594\n",
       "Time:                        11:19:06   Log-Likelihood:                -789.48\n",
       "converged:                       True   LL-Null:                       -1460.3\n",
       "                                        LLR p-value:                4.541e-292\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -11.5405      0.435    -26.544      0.000       -12.393   -10.688\n",
       "balance        0.0056      0.000     24.835      0.000         0.005     0.006\n",
       "income      2.081e-05   4.99e-06      4.174      0.000       1.1e-05  3.06e-05\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error without validation set\n",
    "This is an in-sample prediction. Training error in both sklearn and statsmodels. Both are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97370000000000001"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(X) == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97370000000000001"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((result.predict(X) > .5) * 1 == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-11.69397825]), array([[  5.65294960e-03,   2.39109684e-05]]))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=100000, tol=.0000001)\n",
    "model.fit(X_train, y_train)\n",
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sm = X_train.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078346\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>default_yes</td>   <th>  No. Observations:  </th>   <td>  7500</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  7497</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 30 Aug 2016</td> <th>  Pseudo R-squ.:     </th>   <td>0.4538</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:26:24</td>     <th>  Log-Likelihood:    </th>  <td> -587.60</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1075.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>9.392e-213</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.7115</td> <td>    0.514</td> <td>  -22.775</td> <td> 0.000</td> <td>  -12.719   -10.704</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0057</td> <td>    0.000</td> <td>   21.276</td> <td> 0.000</td> <td>    0.005     0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.402e-05</td> <td> 5.84e-06</td> <td>    4.115</td> <td> 0.000</td> <td> 1.26e-05  3.55e-05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            default_yes   No. Observations:                 7500\n",
       "Model:                          Logit   Df Residuals:                     7497\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Tue, 30 Aug 2016   Pseudo R-squ.:                  0.4538\n",
       "Time:                        11:26:24   Log-Likelihood:                -587.60\n",
       "converged:                       True   LL-Null:                       -1075.8\n",
       "                                        LLR p-value:                9.392e-213\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -11.7115      0.514    -22.775      0.000       -12.719   -10.704\n",
       "balance        0.0057      0.000     21.276      0.000         0.005     0.006\n",
       "income      2.402e-05   5.84e-06      4.115      0.000      1.26e-05  3.55e-05\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = smf.logit(formula='default_yes ~ balance + income', data=X_train_sm).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9728, 0.9728)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nearly the same as training set. So not too much over fitting has happened\n",
    "(model.predict(X_test) == y_test).mean(), ((result.predict(X_test) > .5) * 1 == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation error of only .0272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.076232\n",
      "         Iterations 10\n",
      "0.968 0.968\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.079235\n",
      "         Iterations 10\n",
      "0.974 0.974\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.080995\n",
      "         Iterations 10\n",
      "0.9752 0.9752\n"
     ]
    }
   ],
   "source": [
    "# c) repeat for 3 different validation sets\n",
    "model = LogisticRegression(C=100000, tol=.0000001)\n",
    "\n",
    "for i in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    X_train_sm = X_train.join(y_train)\n",
    "    result = smf.logit(formula='default_yes ~ balance + income', data=X_train_sm).fit()\n",
    "    print((model.predict(X_test) == y_test).mean(), ((result.predict(X_test) > .5) * 1 == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.080539\n",
      "         Iterations 10\n",
      "0.9752 0.9752\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.074620\n",
      "         Iterations 10\n",
      "0.9716 0.9716\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.076308\n",
      "         Iterations 10\n",
      "0.9708 0.9708\n"
     ]
    }
   ],
   "source": [
    "# d) include student in model\n",
    "X = default[['balance', 'income', 'student_yes']]\n",
    "y = default['default_yes']\n",
    "\n",
    "model = LogisticRegression(C=100000, tol=.0000001)\n",
    "\n",
    "for i in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    X_train_sm = X_train.join(y_train)\n",
    "    result = smf.logit(formula='default_yes ~ balance + income + student_yes', data=X_train_sm).fit()\n",
    "    print((model.predict(X_test) == y_test).mean(), ((result.predict(X_test) > .5) * 1 == y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like error rate is very similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6\n",
    "Computing stand errors of coefficents of logistic regression using bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>default_yes</td>   <th>  No. Observations:  </th>   <td> 10000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 30 Aug 2016</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:35:54</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393   -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005     0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05  3.06e-05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            default_yes   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9997\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Tue, 30 Aug 2016   Pseudo R-squ.:                  0.4594\n",
       "Time:                        11:35:54   Log-Likelihood:                -789.48\n",
       "converged:                       True   LL-Null:                       -1460.3\n",
       "                                        LLR p-value:                4.541e-292\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -11.5405      0.435    -26.544      0.000       -12.393   -10.688\n",
       "balance        0.0056      0.000     24.835      0.000         0.005     0.006\n",
       "income      2.081e-05   4.99e-06      4.174      0.000       1.1e-05  3.06e-05\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = smf.logit(formula='default_yes ~ balance + income', data=default).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_params = pd.DataFrame(columns=['Intercept', 'balance', 'income'])\n",
    "for i in range(10000):\n",
    "    default_sample = default.sample(len(default), replace=True)\n",
    "    result = smf.logit(formula='default_yes ~ balance + income', data=default_sample).fit(disp=0)\n",
    "    df_params.append(result.params, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
